# -*- coding: utf-8 -*-
"""Untitled12.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lihUB_ako1kAYVo5S9dEYyv7x4jDGdfi
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sn

from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.preprocessing import LabelEncoder

df = pd.read_csv('/content/Student Mental health.csv')

df.head()

new_columns = ['Time','Gender','Age','Major','Year','CGPA','Marriage','Depression','Anxiety','Panic','Treatment']
df.columns = new_columns
df.head()

df.shape

df.info()

df.describe()

df.dtypes

df.nunique()

df.isnull().sum()

df = df.dropna(how='any',axis=0)

df.isnull().sum()

plt.figure(figsize=(10,10))
plt.hist(df['Age'],color='b')
plt.title("Age distribution")

df['Age'].hist()

plt.title('Age distribution of participants')
plt.xlabel('Age')
plt.ylabel('Frequency')

sn.boxplot(data=df, x='Depression', y='Age')

plt.title('Depression by Age')

sn.histplot(df['CGPA'].sort_values(), kde=True)

plt.title('CGPA distribution')

plt.figure(figsize=(12,6))
plt.title("gender distribution")
g = plt.pie(df.gender.value_counts(), explode=(0.025,0.025), labels=df.gender.value_counts().index, colors=['skyblue','navajowhite'],autopct='%1.1f%%', startangle=180);
plt.legend()
plt.show()

fig=plt.figure(figsize=(8,6))

plt.subplot(1,2,1)
sn.countplot(data=df, x='Marriage', hue='Anxiety')
plt.title('Marriage frequency')

plt.subplot(1,2,2)
sn.countplot(data=df, x='Depression', hue='Marriage')
plt.title("Depression frequency")

df.head()

"""Data Processing

"""

cols=['Marriage','Depression','Anxiety','Panic','Treatment']

def check(x):
  if x=='Yes':
    return 1
  else:
    return 0

for i in cols:
  df[i]=df[i].apply(lambda x:1 if x=='Yes' else 0)

df.head()

df['Year']=df['Year'].apply(lambda x : int(x[-1: ]))

df

df['CGPA'].unique()

df['CGPA'].value_counts().sort_values()

def change_CGPA(x):
  if(x=='3.50 - 4.00') or (x=='3.50 - 4.00'):
    x=5
    return x

  elif (x=='3.00 - 3.49'):
    x=4
    return x

  elif (x=='2.50 - 2.99'):
    x=3
    return x

  elif(x=='2.00 - 2.49'):
    x=2
    return x

  else:
    x=1
    return x

df['CGPA']=df['CGPA'].apply(lambda x : change_CGPA(x))

df.head()

df['Gender']=df['Gender'].apply(lambda x: 0 if x=='Female' else 1)

df['Gender'].unique()

"""we have to handle with Major **Column**


"""

df['Major'].sort_values().unique()

le=LabelEncoder()

df['Major']=le.fit_transform(df['Major'])

df.head()

df.drop('Time',axis=1,inplace=True)

df.head()

"""our Data pre-processing is **done**"""

df

"""**Train Test Split**"""

X=df.drop(columns='Depression', axis=1)
Y=df['Depression']

X

Y

X_train,X_test,Y_train,Y_test=train_test_split(X,Y, test_size=0.2, random_state=42)

print(X.shape, X_train.shape, X_test.shape)

print(Y.shape, Y_train.shape, Y_test.shape)

"""Model"""

model=LogisticRegression()
model.fit(X_train,Y_train)

x_train_pred=model.predict(X_train)
training_accuracy=accuracy_score(Y_train, x_train_pred)

print('Training Accuracy: ',training_accuracy)

x_test_pred=model.predict(X_test)
testing_accuracy=accuracy_score(Y_test, x_test_pred)

print('Training Accuracy: ',testing_accuracy)

input_data = (	0,	19.0,	38,	3,	5,	1,	0,	1	,0)

# change the input data to a numpy array
input_data_as_numpy_array = np.asarray(input_data)

# reshape the numpy array as we are predicting for one datapoint
input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

prediction = model.predict(input_data_reshaped)
print(prediction)

if (prediction[0] == 0):
  print('Not Depressed')

else:
  print('Depressed')

input_data = (0	,21.0	,2	,1	,5	,0	,1	,0	,0)

# change the input data to a numpy array
input_data_as_numpy_array = np.asarray(input_data)

# reshape the numpy array as we are predicting for one datapoint
input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

prediction = model.predict(input_data_reshaped)
print(prediction)

if (prediction[0] == 0):
  print('Not Depressed')

else:
  print('Depressed')

model1=GaussianNB()
model1.fit(X_train,Y_train)

x_train_pred=model1.predict(X_train)
training_accuracy=accuracy_score(Y_train, x_train_pred)

print('Training Accuracy: ',training_accuracy)

x_test_pred=model1.predict(X_test)
testing_accuracy=accuracy_score(Y_test, x_test_pred)

print('Training Accuracy: ',testing_accuracy)

input_data = (	0,	19.0,	38,	3,	5,	1,	0,	1	,0)

# change the input data to a numpy array
input_data_as_numpy_array = np.asarray(input_data)

# reshape the numpy array as we are predicting for one datapoint
input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

prediction = model1.predict(input_data_reshaped)
print(prediction)

if (prediction[0] == 0):
  print('Not Depressed')

else:
  print('Depressed')

input_data = (0	,21.0	,2	,1	,5	,0	,1	,0	,0)

# change the input data to a numpy array
input_data_as_numpy_array = np.asarray(input_data)

# reshape the numpy array as we are predicting for one datapoint
input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

prediction = model1.predict(input_data_reshaped)
print(prediction)

if (prediction[0] == 0):
  print('Not Depressed')

else:
  print('Depressed')

import pickle

filename='Depression_prediction.sav'
pickle.dump(model, open(filename, 'wb'))

loaded_model=pickle.load(open('Depression_prediction.sav', 'rb'))

for column in X.columns:
  print(column)

!pip install seaborn matplotlib

import seaborn as sns

df = pd.read_csv('/content/Student Mental health.csv')

sns.set(style="whitegrid")
plt.figure(figsize=(10, 6))